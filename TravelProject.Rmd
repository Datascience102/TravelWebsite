---
title: "A Market Segmentation and Purchase Drivers Process"
author: "Alessandro Quintarelli, Marcelo Santiso, Oreste Gasparro"
output:
  html_document:
    css: AnalyticsStyles/default.css
    theme: paper
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    includes:
      in_header: AnalyticsStyles/default.sty
always_allow_html: yes
#render("TravelProject.Rmd", html_document())
---
```{r setuplibraries, echo=FALSE, message=FALSE}
source("Library/Library.R")
#source("Library/allPublicLibraries.R")
#source("Library/heatmapOutput.R")
source("Library/helpersSet1.R")
source("Library/helpersSet2.R")
source("Library/MartrixOperations.R")

#ggthemr('fresh')  # ggplot theme
#pts_knit$set(progress=FALSE, verbose=FALSE)
#opts_chunk$set(echo=FALSE, fig.align="center", fig.width=10, fig.height=6.5)
#options(knitr.kable.NA = '')

```

ABC Hotels & Resorts is a hotel chain based in Spain, specializing in 4 and 5 star hotels, owned by Grupo ABC.

The client has its own website, which allows for online booking and receives traffic from several countries.

### The Business Questions

Identify the main customer segments and define market strategies to increase revenues generated.

### The Process

The process we followed can be splitted in 2 different parts:

**Part 1**: Data set inspection and dimensionality reduction

**Part 2**: Data analysis and marketing insights

**Part 3**: Final recommendation and strategy

<hr>\clearpage

# Part 1 - Data Inspection

### Key Customer Characteristics

First we load the data to use:

```{r, echo=FALSE, tidy=TRUE}
myData <- read.csv(file = "Data/Iberostar.csv", header = TRUE, sep=",")
MIN_VALUE = 0.5
```

The data refer to the users and their interaction with the website until that time.
Overall the dataset contains information on 667 customers described by 19 number of variables.

Variables description: <br>
<ul>
<li> Type of User: Returning or New Visitor </li>
<li> Source: Organic vs Paid Promotions (cpc, cpm, referral) </li>
<li> Users: Number of User Visits </li>
<li> Sessions: Number of User Sessions </li>
<li> No of Pages Visited: Number of total pages visited </li>
<li> No of Transactions: Number of monetary transactions </li>
<li> Revenue: Revenue generated </li>
<li> Dummy Variable: We created dummy variables categorical data such as 'user type', 'source' and 'device type'  </li>
</ul>
  

```{r}
factor_attributes_used = c(1:19)
factor_selectionciterion = 
minimum_variance_explained = 65
manual_numb_factors_used = 5
rotation_used = "varimax"
max_data_report = 5
factor_attributes_used <- intersect(factor_attributes_used, 1:ncol(myData))
ProjectDataFactor <- myData[,factor_attributes_used]
ProjectDataFactor <- as.matrix(ProjectDataFactor)
```

### Check the Data 


Start by some basic visual exploration of, say, a few data:

<p align="center"> **Data Visualization** </p>

```{r, echo=FALSE, tidy=TRUE}
rownames(ProjectDataFactor) <- paste0("Customer", sprintf("%02i", 1:nrow(ProjectDataFactor)))
knitr::kable(t(head(ProjectDataFactor, max_data_report)))
```


### Check Correlations

We can then analyze the data in terms of correlation between different variables.
In this way we have a first idea of possible cross-relationships between variables that could lead to a dimensionality reduction in our analysis.

<p align="center"> **Correlation Table** </p>

```{r, echo=FALSE, tidy=TRUE}
thecor = round(cor(myData[,4:19]),2)
knitr::kable(round(thecor,2), scale=TRUE)
```

From correlation matrix we can see that there is a good positive correlation between number of Sessions, number of pages visited, number of transactions and revenues.
We can also see that Desktop device is the one that generates most of the traffic and revenues in absolute value.


### Choose number of factors

To use Factor Analysis, we first need to adjust data to have only numeric data. 
We can then remove first columns and keep only binary values.

```{r}
num_data <- myData[,4:ncol(myData)]
scaled_data <- apply(num_data,2, function(r) {if (sd(r)!=0) res=(r-mean(r))/sd(r) else res=0*r; res})
```

Now that we have only numeric data, we can proceed with Factor Analysis.

```{r}
Variance_Explained_Table_results<-PCA(scaled_data, graph=FALSE)
Variance_Explained_Table<-Variance_Explained_Table_results$eig
Variance_Explained_Table<-as.data.frame(Variance_Explained_Table)
colnames(Variance_Explained_Table)<-c("Eigenvalue", "Percentage_of_explained_variance", "Cumulative_percentage_of_explained_variance")

eigenvalues  <- Variance_Explained_Table[,2]
```

Let's look at the **variance explained** as well as the **eigenvalues**

<p align="center"> **Variance Explained** </p>

```{r, echo=FALSE, tidy=TRUE}
iprint.df(round(Variance_Explained_Table, 2))
```

<p align="center"> **Eigenvalue Plot** </p>

```{r, echo=FALSE, tidy=TRUE}
eigenvalues  <- Variance_Explained_Table[, "Eigenvalue"]
df           <- cbind(as.data.frame(eigenvalues), c(1:length(eigenvalues)), rep(1, length(eigenvalues)))
colnames(df) <- c("eigenvalues", "components", "abline")
iplot.df(melt(df, id="components"))
```

### Interpret the Components

We can see from the chart above that we could use only 8 components.
This can be easily explained looking at the variables. Some variables are binary values conveying the same meaning as the text variables. 
We can identify the following groups:

<ul>
<li> Device </li>
<li> Returning/New Visitor </li>
<li> Source </li>
<li> Revenues </li>
<li> Number of Sessions </li>
<li> Number of pages visited </li>
<li> Number of Users </li>
<li> Number of Transactions </li>
</ul>

In this case we suggest to keep all the original variables since they are just a way to provide the same information in a binary form.

<hr>\clearpage

# Part 2: Marketing Strategy

To analyze different scenarios and identify possible strategies, we can focus on different behaviors across devices.

```{r}
averageTransaction <- aggregate(myData$No.of.Transactions,list(myData$Device), FUN=sum)
colnames(averageTransaction) <- c("Device","No of Transactions")
knitr::kable(averageTransaction)
```

We can clearly see that desktop is the main channel used by customers to access the website, generating about 95% of total transactions.
We can now focus on revenues to check if we find the same trend or a different behavios depending on the device.

```{r}
averageRevenue <- aggregate(myData$Revenue,list(myData$Device), FUN=sum)
colnames(averageRevenue) <- c("Device","Revenues")
knitr::kable(averageRevenue)
```
Even an analysis on revenues shows that desktop is the most used device, as expected from previous result.
We can then analyze revenues per transaction to check profitability for each device.

```{r}
RevTransaction <- averageRevenue
RevTransaction[,2] <- averageRevenue[,2]/averageTransaction[,2] 
colnames(RevTransaction) <- c("Device","Revenue per Transaction")
knitr::kable(RevTransaction)
```

We can see that revenues per transaction are quite stable cross-device, even though tablet is more profitable if compared to desktop and mobile devices.

Moving from devices to sources, we can then compare organic sources to payed sources (e.g. "cpc") and see if there is a strong relationship between transaction and revenues and different sources.

```{r}
averageRevenueSource <- aggregate(myData$Revenue,list(myData$Source), FUN=sum)
colnames(averageRevenueSource) <- c("Source","Revenues")
averageRevenueSource <- averageRevenueSource[order(averageRevenueSource[,2],averageRevenueSource[,1],decreasing=TRUE),]
rownames(averageRevenueSource) <- c(1:nrow(averageRevenueSource))
knitr::kable(averageRevenueSource[1:10,])
```

Focusing on top 10 sources, we can see that direct access and organic searches on google or bing provide more than 4 times the revenues of payed sources like "cpc" and "cpm".

<hr>\clearpage

# Part 3: Recommendation

From previous analysis, we can suggest the following strategy:
* reduce spending in payed sources;
* provide app/mobile portal to facilitate the access from tablet;
* .....

